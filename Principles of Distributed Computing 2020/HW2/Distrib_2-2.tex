\documentclass[]{article}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{color}
\usepackage[margin=1.2in]{geometry}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
%opening
\title{}
\author{}

\begin{document}

\section*{CONGEST Model - MST}
\textbf{Consider a weighted network graph $G = (V,E,w)$ with $n$ vertices, each representing a computer, with unique identifiers $1,...,n$, where the weight $w(e)$ of each edge is known to its endpoints. We consider the following variant of the CONGEST model: Per round, each computer can send (potentially different) $O( n^{1/2}  \log n)$-bit messages to its neighbors. Suppose that $D$ denotes the diameter of $G$ and all computers know the values of $n$ and $D$.}

\textbf{Devise a distributed algorithm that computes a minimum spanning tree (MST) of $G$ in $O((D + n^{1/4})\log n)$ rounds. Your algorithm may be randomized, but should finish within the desired number of rounds with high probability, i.e. with probability at least $1 - n^{-c}$ for any fixed constant $c$.}\\

\underline{Used notation} (for notationally accurate reader): something like $f(n)=O(...)$ here means in rigorous notation $f(n) \in O(...))$. When something is deduced from $O(...)$ or $\Omega(...)$ in formulas, it means it works for any function set from this sets (e.g. $\frac{n^2}{n} = \frac{O(n^2)}{\Omega(n)}=O(n)$ means rigorously $\frac{n^2}{n} \in S, S = \{\text{functions f s. t. }f=h/g, h\in O(n^2), g\in \Omega(n)\}), \text{ and } S = O(n)$ as sets.\\

\textbf{Solution:}\\
We use the same algorithm (Boruvka's) described in sections 2.2.1 and 2.2.3 of lecture notes \cite{Ghaffari}, but at the stage when components are divided to small and big, we use threshold $n^{3/4}$. It means, that for larger components, which number is no more than $n^{1/4}$ now, using described there pipelining we'll have phase complexity $O(D+n^{1/4})$.\\

For smaller components if we used the same algorithm, the phase cost will be $O(n^{3/4})$ which could be unacceptable if e.g. $D\ll n$. But we use instead of convergecast or flooding, the idea from the exercise 1b for lecture 10 \cite{ex10, sol10}.\\

The task there was to distribute among all the nodes $k$ messages which are initially stored each only in one node (as information of minimum--weight edges from all nodes to the leader; bit head--tail and number of nodes in group from leader to others). But we modify it in a way that now node can send not one, but $O(\sqrt{n})$ messages (say $C*\sqrt{n}$ for some independent constant $C$; we go from $O$--notation to constant only to show that further in the modified solution of 1b number of messages node can send is bounded), which complies with the extended communication abilities of nodes defined in this task. Therefore, in the solution of exercise 1b \cite{sol10}, the claim is that the node $v$ has sent message $m$ or $lC\sqrt{n}$ other messages. Nothing else changes in the solution (so at the end of $t-1$ round $v$ has sent $m$ or $(l-1)C\sqrt{n}$ other messages, and $v'$ has sent $m$ or $((t-1)-(d-1))C\sqrt{n} = lC\sqrt{n}$ other messages, which concludes the proof of 1b with changed complexity $O(D+n^{1/4})$ (because in $t=d+l$ we have that from the whole number of messages when all messages (one for each node) are delivered: $O(n^{3/4})\ge lC\sqrt{n} \Rightarrow l = O(n^{1/4})l \Rightarrow t = O(D+n^{1/4})$), what needed.\\

Therefore, we made complexity of each phase $O(D+n^{1/4})$ instead of $O(D+\sqrt{n})$, which leads after $O(\log n)$ phases to overall complexity $O\left((D+n^{1/4})\log n\right)$.

\bibliographystyle{ieeetr}
\bibliography{bib_distrib}
\end{document}